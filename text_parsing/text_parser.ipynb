{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cdef3c4-6ba3-4938-a712-18f0fc032a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "\n",
    "from datetime import datetime\n",
    "from apache_beam.options import pipeline_options\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.runners import DataflowRunner\n",
    "\n",
    "import apache_beam.runners.interactive.interactive_beam as ib\n",
    "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e1aaac-c314-4705-8a27-24c60a4322be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open ./data/data_archive.zip, ./data/data_archive.zip.zip or ./data/data_archive.zip.ZIP.\n",
      "bzip2: Can't open input file train.ft.txt.bz2: No such file or directory.\n",
      "bzip2: Can't open input file test.ft.txt.bz2: No such file or directory.\n",
      "mv: cannot stat '*.ft.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp -r gs://text-analysis-323506/data ./\n",
    "! unzip ./data/data_archive.zip \n",
    "! bzip2 -d train.ft.txt.bz2 \n",
    "! bzip2 -d test.ft.txt.bz2\n",
    "! mv *.ft.txt ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b974d70-c5b7-421f-aac3-ccee7248c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_line(line: str):\n",
    "    contraction_dict = {\"ain't\": \"are not\", \"'s\":\" is\", \"aren't\": \"are not\", \"don't\": \"do not\", \"didn't\": \"did not\", \"won't\": \"will not\", \n",
    "                   \"can't\": \"cannot\"}\n",
    "    \n",
    "    words = line.split()\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in contraction_dict:\n",
    "            words[i] = contraction_dict[words[i]]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f151079-0f47-4562-a950-48828ce14011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower_case(line: str):\n",
    "    return line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33ef7d7a-154a-48ae-95ca-75a3294edb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(line: str):\n",
    "    return line.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd2831e-3632-4b07-b517-65167b9363bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(line: str):\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in line.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3105ccb6-ee42-4af8-a481-759f58d18e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(line: str):\n",
    "    import re\n",
    "    return re.sub('[\\W\\_]','',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5962e8a-80b7-4a0f-8b2d-066863aa96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(line: str):\n",
    "    import re\n",
    "    \n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe14470-03de-44a7-bdc7-d177c799f307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1. Apache Beam 2.33.0 for Python 3",
   "language": "python",
   "name": "1-apache-beam-2.33.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
